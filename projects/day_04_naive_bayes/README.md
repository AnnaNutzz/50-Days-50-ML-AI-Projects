# Day 04 — Naive Bayes 

Naive Bayes is a probabilistic machine learning algorithms based on the Bayes Theorem. It is popular method for classification applications such as spam filtering and text classification.



## What is Naive Bayes?

Naive Bayes is a probabilistic classification algorithm based on Bayes’ Theorem that predicts a class by choosing the one with the highest probability given the input features, while assuming the features are independent of each other.

$P(A/B) = \frac{P(A \cap B)}{P(B)}$

which can be shown as:  

Bayes' formula $P(A/B) = \frac{P(\frac{B}{A})P(A)}{P(B)}$



### Example 1 



|Fruit|Yellow|Sweet|Long|Total
|---|---|---|---|---
|$\bold{Mango}$|350|450|0| $\bold{650}$
|$\bold{Banana}$|400|300|350| $\bold{400}$
|$\bold{mango}$|50|100|50| $\bold{650}$
|$\bold{Total}$|$\bold{800}$|$\bold{850}$|$\bold{400}$|$\bold{1200}$




---

## Limitations of Naive Bayes


---

## What I Learned


---

## References

1. [Gate Smashers – Lec-8: Naive Bayes Classification Full Explanation with examples | Supervised Learning](https://www.youtube.com/watch?v=GBMMtXRiQX0)
2. 